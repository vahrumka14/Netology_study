{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qB1egUSX0gH-"
   },
   "source": [
    "# Кейс-стади -2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "01apPJT-zhCm"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import t\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "from scipy.stats import pearsonr\n",
    "import ssl\n",
    "# следующая строчка подключает сертификат для защищенного соединения\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UB_povh6hYuU"
   },
   "source": [
    "# Байесовский метод решения задачи классификации.\n",
    "\n",
    "Лучшим другом аналитика данных является теорема Байеса, которая позволяет \"переставить\" условные вероятности местами. Пусть нужно узнать вероятность не коего события E, зависящего от наступления некоего другого события F, причем в наличии имеется лишь информация о вероятности события F, зависящего от наступления события E. Двукратное применение (в силу симметрии) определения условной вероятности даст формулу Байеса:\n",
    "\n",
    "\n",
    "$$P(A\\mid B) = \\frac{P(B\\mid A) P(A)}{P(B)}$$\n",
    "\n",
    "где $P(A\\mid B)$ - вероятность наступления события A при условии наличия события B\n",
    "\n",
    "\n",
    "Если событие B разложить на два взаимоисключающих события B при условии A и B при условии $\\bar{A}$, то событие P(B) можно представить как сумма вероятностей наступления событий $P(B\\mid A)$ и  $P(B\\mid \\bar{A})$, тогда формула вероятности примет вид:\n",
    "\n",
    "$$P(A\\mid B) = \\frac{P(B\\mid A) P(A)}{P(B\\mid A)P(A) + P(B\\mid \\bar{A})P(\\bar{A})}$$\n",
    "\n",
    "\n",
    "Если события независимы:\n",
    "\n",
    "$$P(A\\mid B) = P(A)P(B)$$\n",
    "\n",
    "Если события зависимы, и при этом вероятность B не равна нулю, то \n",
    "\n",
    "$$P(A\\mid B) = \\frac{P(A, B) }{P(B)}$$\n",
    "\n",
    "\n",
    "Под этим подразумевается вероятность наступления события A при условии, что известно о наступлении события B.\n",
    "\n",
    "В случае независимости двух переменных формула принимает вид:\n",
    "\n",
    "$$P(A\\mid B) = P(A)$$\n",
    "\n",
    "\n",
    "означает, что наличие наступления события B не дает нам никакой информации о наступлении события A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача. \n",
    "**Определить есть ли болезнь сердца у пациента с определенными показателями.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Датасет больных сердечно-сосудистыми заболеваниями"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Источник: https://www.kaggle.com/sulianova/cardiovascular-disease-dataset"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Data description\n",
    "There are 3 types of input features:\n",
    "\n",
    "Objective: factual information;\n",
    "Examination: results of medical examination;\n",
    "Subjective: information given by the patient.\n",
    "Features:\n",
    "\n",
    "Age | Objective Feature | age | int (days)\n",
    "Height | Objective Feature | height | int (cm) |\n",
    "Weight | Objective Feature | weight | float (kg) |\n",
    "Gender | Objective Feature | gender | categorical code |\n",
    "Systolic blood pressure | Examination Feature | ap_hi | int |\n",
    "Diastolic blood pressure | Examination Feature | ap_lo | int |\n",
    "Cholesterol | Examination Feature | cholesterol | 1: normal, 2: above normal, 3: well above normal |\n",
    "Glucose | Examination Feature | gluc | 1: normal, 2: above normal, 3: well above normal |\n",
    "Smoking | Subjective Feature | smoke | binary |\n",
    "Alcohol intake | Subjective Feature | alco | binary |\n",
    "Physical activity | Subjective Feature | active | binary |\n",
    "Presence or absence of cardiovascular disease | Target Variable | cardio | binary |\n",
    "All of the dataset values were collected at the moment of medical examination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69995</th>\n",
       "      <td>99993</td>\n",
       "      <td>19240</td>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "      <td>76.0</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69996</th>\n",
       "      <td>99995</td>\n",
       "      <td>22601</td>\n",
       "      <td>1</td>\n",
       "      <td>158</td>\n",
       "      <td>126.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69997</th>\n",
       "      <td>99996</td>\n",
       "      <td>19066</td>\n",
       "      <td>2</td>\n",
       "      <td>183</td>\n",
       "      <td>105.0</td>\n",
       "      <td>180</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69998</th>\n",
       "      <td>99998</td>\n",
       "      <td>22431</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>72.0</td>\n",
       "      <td>135</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69999</th>\n",
       "      <td>99999</td>\n",
       "      <td>20540</td>\n",
       "      <td>1</td>\n",
       "      <td>170</td>\n",
       "      <td>72.0</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id    age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  \\\n",
       "69995  99993  19240       2     168    76.0    120     80            1     1   \n",
       "69996  99995  22601       1     158   126.0    140     90            2     2   \n",
       "69997  99996  19066       2     183   105.0    180     90            3     1   \n",
       "69998  99998  22431       1     163    72.0    135     80            1     2   \n",
       "69999  99999  20540       1     170    72.0    120     80            2     1   \n",
       "\n",
       "       smoke  alco  active  cardio  \n",
       "69995      1     0       1       0  \n",
       "69996      0     0       1       1  \n",
       "69997      0     1       0       1  \n",
       "69998      0     0       0       1  \n",
       "69999      0     0       1       0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url=\"http://yustiks.ru/dataset/cardio_train.csv\"\n",
    "data=pd.read_csv(url,sep=\";\")\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сколько человек в таблице всего:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.id.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Визуализируем несколько взаимосвязей между переменными"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Взаимосвязь между переменной weight и ap_hi {Systolic blood pressure}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(data.weight, data.ap_hi)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуализируем взаимосвязь между  weight и ap_lo {Diastolic blood pressure}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(data.weight, data.ap_lo)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуализируем зависимость между ap_hi {Systolic blood pressure} и ap_lo {Diastolic blood pressure}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(data.ap_hi, data.ap_lo)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# С использованием t-test статистики проверим взаимосвязи между несколькими переменными"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как тестировать две переменные, как посчитать степени свободы: https://towardsdatascience.com/inferential-statistics-series-t-test-using-numpy-2718f8f9bf2f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Метод 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-2079.746249421458, pvalue=0.0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_ind(data.weight, data.age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p-value < 0.05, поэтому можно сказать что имеется статистическое различие между атрибутами. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Метод 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Библиотека researchpy: pip install researchpy"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "summary_cont() - \n",
    "Returns a nice data table as a Pandas DataFrame that includes the variable name, total number of non-missing observations, standard deviation, standard error, and the 95% confidence interval."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "https://researchpy.readthedocs.io/en/latest/summary_cont_documentation.html#summary-cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N</th>\n",
       "      <th>Mean</th>\n",
       "      <th>SD</th>\n",
       "      <th>SE</th>\n",
       "      <th>95% Conf.</th>\n",
       "      <th>Interval</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cardio</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35021</td>\n",
       "      <td>1.345707</td>\n",
       "      <td>0.475605</td>\n",
       "      <td>0.002541</td>\n",
       "      <td>1.340726</td>\n",
       "      <td>1.350688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34979</td>\n",
       "      <td>1.353441</td>\n",
       "      <td>0.478045</td>\n",
       "      <td>0.002556</td>\n",
       "      <td>1.348431</td>\n",
       "      <td>1.358451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            N      Mean        SD        SE  95% Conf.  Interval\n",
       "cardio                                                          \n",
       "0       35021  1.345707  0.475605  0.002541   1.340726  1.350688\n",
       "1       34979  1.353441  0.478045  0.002556   1.348431  1.358451"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import researchpy as rp\n",
    "# Showing descriptive statistics from researchpy.summary_cont()\n",
    "rp.summary_cont(data.groupby('cardio')['gender'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N - количество элементов\n",
    "Mean - среднее значение\n",
    "SD - стандартное отклонение\n",
    "SE - стандартная ошибка (https://ru.wikipedia.org/wiki/Стандартная_ошибка)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция для подсчета t-test: https://researchpy.readthedocs.io/en/latest/ttest_documentation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>N</th>\n",
       "      <th>Mean</th>\n",
       "      <th>SD</th>\n",
       "      <th>SE</th>\n",
       "      <th>95% Conf.</th>\n",
       "      <th>Interval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cardio</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>0.499700</td>\n",
       "      <td>0.500003</td>\n",
       "      <td>0.001890</td>\n",
       "      <td>0.495996</td>\n",
       "      <td>0.503404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>weight</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>74.205690</td>\n",
       "      <td>14.395757</td>\n",
       "      <td>0.054411</td>\n",
       "      <td>74.099045</td>\n",
       "      <td>74.312335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>combined</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>37.352695</td>\n",
       "      <td>38.234750</td>\n",
       "      <td>0.102187</td>\n",
       "      <td>37.152411</td>\n",
       "      <td>37.552979</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Variable         N       Mean         SD        SE  95% Conf.   Interval\n",
       "0    cardio   70000.0   0.499700   0.500003  0.001890   0.495996   0.503404\n",
       "1    weight   70000.0  74.205690  14.395757  0.054411  74.099045  74.312335\n",
       "2  combined  140000.0  37.352695  38.234750  0.102187  37.152411  37.552979"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptives, results = rp.ttest(data.cardio, data.weight)\n",
    "\n",
    "descriptives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Independent t-test</th>\n",
       "      <th>results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Difference (cardio - weight) =</td>\n",
       "      <td>-73.7060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Degrees of freedom =</td>\n",
       "      <td>139998.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t =</td>\n",
       "      <td>-1353.8031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Two side test p value =</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Difference &lt; 0 p value =</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Difference &gt; 0 p value =</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Cohen's d =</td>\n",
       "      <td>-7.2364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hedge's g =</td>\n",
       "      <td>-7.2363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Glass's delta =</td>\n",
       "      <td>-147.4110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>r =</td>\n",
       "      <td>0.9639</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Independent t-test      results\n",
       "0  Difference (cardio - weight) =      -73.7060\n",
       "1            Degrees of freedom =   139998.0000\n",
       "2                             t =    -1353.8031\n",
       "3         Two side test p value =        0.0000\n",
       "4        Difference < 0 p value =        0.0000\n",
       "5        Difference > 0 p value =        1.0000\n",
       "6                     Cohen's d =       -7.2364\n",
       "7                     Hedge's g =       -7.2363\n",
       "8                 Glass's delta =     -147.4110\n",
       "9                             r =        0.9639"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "two-side p-value < 0.05, поэтому можно сказать что имеется статистическое различие между атрибутами. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Difference (cardio - weight) = разница между средними двух атрибутов\n",
    "Degrees of freedom = степени свободы для двух атрибутов\n",
    "t = t-value\n",
    "Two side test p value =\tpvalue\n",
    "Difference < 0 p value = pvalue для гипотезы, что разницы между двумя переменными отсутствует\n",
    "Difference > 0 p value = pvalue для гипотезы, что разница между двумя переменными есть\n",
    "Cohen's d = https://researchpy.readthedocs.io/en/latest/ttest_documentation.html#cohen-s-dz-within-subject-design\n",
    "Hedge's g = https://researchpy.readthedocs.io/en/latest/ttest_documentation.html#hedges-s-gs-between-subjects-design\n",
    "Glass's delta = https://researchpy.readthedocs.io/en/latest/ttest_documentation.html#glass-s-delta-between-or-within-subjects-design\n",
    "r = коэффициент корреляции Пирсона"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>18393</td>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "      <td>62.0</td>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20228</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>85.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>18857</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64.0</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>17623</td>\n",
       "      <td>2</td>\n",
       "      <td>169</td>\n",
       "      <td>82.0</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>17474</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>56.0</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  \\\n",
       "0   0  18393       2     168    62.0    110     80            1     1      0   \n",
       "1   1  20228       1     156    85.0    140     90            3     1      0   \n",
       "2   2  18857       1     165    64.0    130     70            3     1      0   \n",
       "3   3  17623       2     169    82.0    150    100            1     1      0   \n",
       "4   4  17474       1     156    56.0    100     60            1     1      0   \n",
       "\n",
       "   alco  active  cardio  \n",
       "0     0       1       0  \n",
       "1     0       1       1  \n",
       "2     0       0       1  \n",
       "3     0       1       1  \n",
       "4     0       0       0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Протестируем гипотезу, что женщины болеют чаще чем мужчины"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "female = data[data['gender']==1].cardio\n",
    "male = data[data['gender']==2].cardio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptives, results = rp.ttest(female, male)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напечатаем результат:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Variable        N      Mean        SD        SE  95% Conf.  Interval\n",
      "0    cardio  45530.0  0.496727  0.499995  0.002343   0.492135  0.501320\n",
      "1    cardio  24470.0  0.505231  0.499983  0.003196   0.498966  0.511496\n",
      "2  combined  70000.0  0.499700  0.500003  0.001890   0.495996  0.503404\n",
      "_______________________________________\n",
      "                Independent t-test     results\n",
      "0  Difference (cardio - cardio) =      -0.0085\n",
      "1            Degrees of freedom =   69998.0000\n",
      "2                             t =      -2.1456\n",
      "3         Two side test p value =       0.0319\n",
      "4        Difference < 0 p value =       0.0160\n",
      "5        Difference > 0 p value =       0.9840\n",
      "6                     Cohen's d =      -0.0170\n",
      "7                     Hedge's g =      -0.0170\n",
      "8                 Glass's delta =      -0.0170\n",
      "9                             r =       0.0081\n"
     ]
    }
   ],
   "source": [
    "print(descriptives)\n",
    "print('_______________________________________')\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно заметить, что есть разница между женщинами и мужчинами (pvalue<0.05). Возможно это связано с тем, что женщин в выборке в 2 раза больше чем мужчин."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проверим гипотезу о том, что люди с показателем cholesterol = 2 болеют чаще"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "chol_2 = data[data['cholesterol']==2].cardio\n",
    "chol_all = data[data['cholesterol']!=2].cardio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Variable        N      Mean        SD        SE  95% Conf.  Interval\n",
      "0    cardio   9549.0  0.602157  0.489478  0.005009   0.592339  0.611976\n",
      "1    cardio  60451.0  0.483516  0.499732  0.002033   0.479532  0.487499\n",
      "2  combined  70000.0  0.499700  0.500003  0.001890   0.495996  0.503404\n",
      "_____________________________\n",
      "                Independent t-test     results\n",
      "0  Difference (cardio - cardio) =       0.1186\n",
      "1            Degrees of freedom =   69998.0000\n",
      "2                             t =      21.6191\n",
      "3         Two side test p value =       0.0000\n",
      "4        Difference < 0 p value =       1.0000\n",
      "5        Difference > 0 p value =       0.0000\n",
      "6                     Cohen's d =       0.2381\n",
      "7                     Hedge's g =       0.2381\n",
      "8                 Glass's delta =       0.2424\n",
      "9                             r =       0.0814\n"
     ]
    }
   ],
   "source": [
    "descriptives, results = rp.ttest(chol_2, chol_all)\n",
    "print(descriptives)\n",
    "print('_____________________________')\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p value = 0.0000, то отличие людей с показателем chol = 2 значительное"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=21.619123191535245, pvalue=2.5898307558677926e-103)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_ind(chol_2, chol_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значит, люди с показателем chol=2 болеют чаще, чем остальные (среднее значение выборки больше чем остальных)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проверим гипотезу о том, что люди, которые курят, болеют чаще сердечной болезнью"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Variable        N      Mean        SD        SE  95% Conf.  Interval\n",
      "0    cardio   6169.0  0.474793  0.499405  0.006358   0.462329  0.487258\n",
      "1    cardio  63831.0  0.502107  0.499999  0.001979   0.498228  0.505986\n",
      "2  combined  70000.0  0.499700  0.500003  0.001890   0.495996  0.503404\n",
      "_____________________________\n",
      "                Independent t-test     results\n",
      "0  Difference (cardio - cardio) =      -0.0273\n",
      "1            Degrees of freedom =   69998.0000\n",
      "2                             t =      -4.0976\n",
      "3         Two side test p value =       0.0000\n",
      "4        Difference < 0 p value =       0.0000\n",
      "5        Difference > 0 p value =       1.0000\n",
      "6                     Cohen's d =      -0.0546\n",
      "7                     Hedge's g =      -0.0546\n",
      "8                 Glass's delta =      -0.0547\n",
      "9                             r =       0.0155\n"
     ]
    }
   ],
   "source": [
    "smoke = data[data['smoke']==1].cardio\n",
    "no_smoke = data[data['smoke']==0].cardio\n",
    "descriptives, results = rp.ttest(smoke, no_smoke)\n",
    "print(descriptives)\n",
    "print('_____________________________')\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Difference > 0 p value = 1.0000, значит, различие в двух выборках значительное.  Среднее значение по атрибуту cardio у курящих 0.47, среднее значение среди некурящих 0.50, скорее связано с тем, что выборки имеют разное количество элементов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-4.097626290112295, pvalue=4.1787798766011306e-05)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_ind(smoke, no_smoke)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача:  создать модель, предсказывающую наличие болезни по параметрам, заданным в таблице"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69995</th>\n",
       "      <td>99993</td>\n",
       "      <td>19240</td>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "      <td>76.0</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69996</th>\n",
       "      <td>99995</td>\n",
       "      <td>22601</td>\n",
       "      <td>1</td>\n",
       "      <td>158</td>\n",
       "      <td>126.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69997</th>\n",
       "      <td>99996</td>\n",
       "      <td>19066</td>\n",
       "      <td>2</td>\n",
       "      <td>183</td>\n",
       "      <td>105.0</td>\n",
       "      <td>180</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69998</th>\n",
       "      <td>99998</td>\n",
       "      <td>22431</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>72.0</td>\n",
       "      <td>135</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69999</th>\n",
       "      <td>99999</td>\n",
       "      <td>20540</td>\n",
       "      <td>1</td>\n",
       "      <td>170</td>\n",
       "      <td>72.0</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id    age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  \\\n",
       "69995  99993  19240       2     168    76.0    120     80            1     1   \n",
       "69996  99995  22601       1     158   126.0    140     90            2     2   \n",
       "69997  99996  19066       2     183   105.0    180     90            3     1   \n",
       "69998  99998  22431       1     163    72.0    135     80            1     2   \n",
       "69999  99999  20540       1     170    72.0    120     80            2     1   \n",
       "\n",
       "       smoke  alco  active  cardio  \n",
       "69995      1     0       1       0  \n",
       "69996      0     0       1       1  \n",
       "69997      0     1       0       1  \n",
       "69998      0     0       0       1  \n",
       "69999      0     0       1       0  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = data.drop(['id', 'cardio'], axis=1), data.cardio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.588076</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.579487</td>\n",
       "      <td>0.273684</td>\n",
       "      <td>0.016079</td>\n",
       "      <td>0.013550</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.730159</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.517949</td>\n",
       "      <td>0.394737</td>\n",
       "      <td>0.017934</td>\n",
       "      <td>0.014453</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.624003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.564103</td>\n",
       "      <td>0.284211</td>\n",
       "      <td>0.017316</td>\n",
       "      <td>0.012647</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.528455</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.584615</td>\n",
       "      <td>0.378947</td>\n",
       "      <td>0.018553</td>\n",
       "      <td>0.015357</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.516918</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.517949</td>\n",
       "      <td>0.242105</td>\n",
       "      <td>0.015461</td>\n",
       "      <td>0.011743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0    1         2         3         4         5    6    7    8    9  \\\n",
       "0  0.588076  1.0  0.579487  0.273684  0.016079  0.013550  0.0  0.0  0.0  0.0   \n",
       "1  0.730159  0.0  0.517949  0.394737  0.017934  0.014453  1.0  0.0  0.0  0.0   \n",
       "2  0.624003  0.0  0.564103  0.284211  0.017316  0.012647  1.0  0.0  0.0  0.0   \n",
       "3  0.528455  1.0  0.584615  0.378947  0.018553  0.015357  0.0  0.0  0.0  0.0   \n",
       "4  0.516918  0.0  0.517949  0.242105  0.015461  0.011743  0.0  0.0  0.0  0.0   \n",
       "\n",
       "    10  \n",
       "0  1.0  \n",
       "1  1.0  \n",
       "2  0.0  \n",
       "3  1.0  \n",
       "4  0.0  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "np_scaled = min_max_scaler.fit_transform(x)\n",
    "df_norm = pd.DataFrame(np_scaled)\n",
    "df_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_norm,y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем модель **Наивный Байес**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy of our model: 0.5932857142857143\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb = GaussianNB()\n",
    "nb.fit(x_train,y_train)\n",
    "print(\"the accuracy of our model: {}\".format(nb.score(x_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.87      0.68      6988\n",
      "           1       0.71      0.32      0.44      7012\n",
      "\n",
      "    accuracy                           0.59     14000\n",
      "   macro avg       0.64      0.59      0.56     14000\n",
      "weighted avg       0.64      0.59      0.56     14000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, nb.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "our accuracy is: 0.6545714285714286\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(max_iter = 200)\n",
    "lr.fit(x_train,y_train)\n",
    "print(\"our accuracy is: {}\".format(lr.score(x_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.68      0.66      6988\n",
      "           1       0.66      0.63      0.65      7012\n",
      "\n",
      "    accuracy                           0.65     14000\n",
      "   macro avg       0.66      0.65      0.65     14000\n",
      "weighted avg       0.66      0.65      0.65     14000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, lr.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очень низкий recall - это может быть связано с **несбалансированностью классов**. Сравним модель **Наивного Байеса** с моделью **Random Forest**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# создаем модель деревья решений\n",
    "# выбираем 100 деревьев в качестве параметра\n",
    "model=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "# обучаем модель\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель Random Forest дает лучше результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.73      0.72      6988\n",
      "           1       0.72      0.70      0.71      7012\n",
      "\n",
      "    accuracy                           0.71     14000\n",
      "   macro avg       0.71      0.71      0.71     14000\n",
      "weighted avg       0.71      0.71      0.71     14000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_pred = model.predict(x_test)\n",
    "\n",
    "print(classification_report(y_test, model_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Определение СПАМа в тексте"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XvItYzkj6nUK"
   },
   "source": [
    "Датасет для определения СПАМа в тексте.  https://www.kaggle.com/team-ai/spam-text-message-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "Df9gsOk36YpQ",
    "outputId": "ddc3a729-c218-494e-9e0a-8e30856a163d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Category                                            Message\n",
       "5567     spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568      ham               Will ü b going to esplanade fr home?\n",
       "5569      ham  Pity, * was in mood for that. So...any other s...\n",
       "5570      ham  The guy did some bitching but I acted like i'd...\n",
       "5571      ham                         Rofl. Its true to its name"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url='http://yustiks.ru/dataset/SPAM_text.csv'\n",
    "data=pd.read_csv(url) \n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "jvKJuvWXaNqw",
    "outputId": "76fcd9a3-c1a0-4f6b-e98a-76c12f2243e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n"
     ]
    }
   ],
   "source": [
    "print(data.loc[2, 'Message'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим новый атрибут Category, где будем указывать, что если данный текст является СПАМом, то 1, если не является, то 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DiBSfYAu7E3J"
   },
   "outputs": [],
   "source": [
    "data[\"Category\"] = [1 if each == \"spam\" else 0 for each in data[\"Category\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "DxJF-FT57GgK",
    "outputId": "3e1a5e9d-4442-4880-e766-7ced24846726"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Category                                            Message\n",
       "0         0  Go until jurong point, crazy.. Available only ...\n",
       "1         0                      Ok lar... Joking wif u oni...\n",
       "2         1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3         0  U dun say so early hor... U c already then say...\n",
       "4         0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a9Vu6XzsBfWw"
   },
   "source": [
    "Как на основе текста предсказать, что он является СПАМом? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bwcux5EgBqJN"
   },
   "source": [
    "# Словарь BAG-of-words. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gAuXKIzSB-82"
   },
   "source": [
    "Создаем слова. На основе слов пишем для каждого текста словарь, где каждое слово - это ключ, а значение ключа - это сколько раз встречается данное слова в данном тексте."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zyjsN0ZqPPgn"
   },
   "source": [
    "Как пример: рассмотрим 1 строку из датасета.\n",
    "\n",
    "\n",
    "\n",
    "*   Удалим все символы, не являющимися латинскими буквами\n",
    "*   Заглавные буквы меняем на строчные\n",
    "*   Разделим текст на слова\n",
    "*   В каждом слове выделяем корень слова\n",
    "*   Создаем список всех слов\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "rq4UlSZkNH-E",
    "outputId": "2706c926-e86a-4b89-ad4f-b616c6782465"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "nlp_data = str(data.loc[2, 'Message'])\n",
    "print(nlp_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0E_4QMsONv3v"
   },
   "source": [
    "Удаление всех не латинских букв:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "yRM_Ykz3NJvK",
    "outputId": "8a8de0e0-e526-4e18-ff00-14cedfac6e45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Free entry in   a wkly comp to win FA Cup final tkts   st May       Text FA to       to receive entry question std txt rate T C s apply            over   s\n"
     ]
    }
   ],
   "source": [
    "nlp_data = re.sub(\"[^a-zA-Z]\",\" \", nlp_data)\n",
    "print(nlp_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y_TIDOgsN-Y_"
   },
   "source": [
    "Во всех словах заглавные буквы меняем на строчные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "qzy8kpblN5aE",
    "outputId": "345d4441-b118-4223-b7d4-94e554191a64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "free entry in   a wkly comp to win fa cup final tkts   st may       text fa to       to receive entry question std txt rate t c s apply            over   s\n"
     ]
    }
   ],
   "source": [
    "nlp_data = nlp_data.lower()\n",
    "print(nlp_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5ibxAPXnOgvj"
   },
   "source": [
    "Переводим текст в отдельные слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "XOhX6nvMOPJD",
    "outputId": "dfbec726-4992-4077-f1d7-e5c92168ccab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['free', 'entry', 'in', 'a', 'wkly', 'comp', 'to', 'win', 'fa', 'cup', 'final', 'tkts', 'st', 'may', 'text', 'fa', 'to', 'to', 'receive', 'entry', 'question', 'std', 'txt', 'rate', 't', 'c', 's', 'apply', 'over', 's']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/yustinaivanova/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk as nlp # библиотека nltk -> pip install nltk \n",
    "nlp.download('punkt')\n",
    "nlp_data = nlp.word_tokenize(nlp_data)\n",
    "print(nlp_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5dpudpmrO_Tp"
   },
   "source": [
    "Ищем корень каждого слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "hbPUYfsTOo9o",
    "outputId": "31f936e5-61e1-4e48-8d43-842b52261f4a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/yustinaivanova/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['free', 'entry', 'in', 'a', 'wkly', 'comp', 'to', 'win', 'fa', 'cup', 'final', 'tkts', 'st', 'may', 'text', 'fa', 'to', 'to', 'receive', 'entry', 'question', 'std', 'txt', 'rate', 't', 'c', 's', 'apply', 'over', 's']\n"
     ]
    }
   ],
   "source": [
    "nlp.download('wordnet')\n",
    "lemma = nlp.WordNetLemmatizer()\n",
    "nlp_data = [lemma.lemmatize(word) for word in nlp_data]\n",
    "print(nlp_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "40keBPrTCLqB"
   },
   "source": [
    "Добавляем все найденные слова в список"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3O1MxC11PJ70"
   },
   "outputs": [],
   "source": [
    "nlp_data = \" \".join(nlp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aWpIjfZiQk8u"
   },
   "outputs": [],
   "source": [
    "description_list = []\n",
    "for description in data[\"Message\"]:\n",
    "    description = re.sub(\"[^a-zA-Z]\",\" \",description)\n",
    "    description = description.lower()\n",
    "    description = nlp.word_tokenize(description)\n",
    "    lemma = nlp.WordNetLemmatizer()\n",
    "    description = [ lemma.lemmatize(word) for word in description]\n",
    "    description = \" \".join(description)\n",
    "    description_list.append(description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сколько всего получилось слов в словаре мешка слов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Yb7nm-_YcDQd",
    "outputId": "3fe4bd78-1d3c-498e-ab4c-7e18bd161733"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5572"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(description_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xloAtHs2dw3U",
    "outputId": "a459b93e-4ccf-401c-9afc-09c02c66a941"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go until jurong point crazy available only in bugis n great world la e buffet cine there got amore wat\n"
     ]
    }
   ],
   "source": [
    "print(description_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xZBGlFp0Q2NW"
   },
   "source": [
    "Создаем bag-of-words, для этого выбираем 3000 максимально встречаемых слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "uH0OST_KQ4gj",
    "outputId": "45c24f21-fb14-4016-b4fc-1dc0dc8cd90f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Самые часто встречаемые 3000 слов: ['aah', 'aathi', 'abi', 'ability', 'abiola', 'abj', 'able', 'absolutly', 'abt', 'abta', 'aburo', 'ac', 'academic', 'acc', 'accept', 'access', 'accident', 'accidentally', 'accordingly', 'account', 'ache', 'acl', 'aco', 'acted', 'acting', 'action', 'activate', 'active', 'activity', 'actor', 'actual', 'actually', 'ad', 'adam', 'add', 'addamsfa', 'added', 'addicted', 'addie', 'address', 'admin', 'administrator', 'admirer', 'admit', 'adore', 'adoring', 'adult', 'advance', 'adventure', 'advice', 'advise', 'ae', 'aeronautics', 'aeroplane', 'affair', 'affection', 'afraid', 'aft', 'afternoon', 'aftr', 'ag', 'agalla', 'age', 'agent', 'ago', 'agree', 'ah', 'aha', 'ahead', 'ahmad', 'aid', 'aight', 'ain', 'aint', 'air', 'airport', 'airtel', 'aiya', 'aiyah', 'aiyar', 'aiyo', 'aj', 'aka', 'al', 'alaipayuthe', 'album', 'alcohol', 'alert', 'alex', 'alfie', 'algarve', 'ali', 'alive', 'allah', 'allow', 'allowed', 'alright', 'alrite', 'alwys', 'amazing', 'american', 'amp', 'amt', 'amused', 'amy', 'andros', 'angry', 'animation', 'anna', 'annie', 'anniversary', 'announcement', 'annoying', 'anot', 'ansr', 'answer', 'answered', 'answering', 'anthony', 'anti', 'anybody', 'anymore', 'anythin', 'anytime', 'anyways', 'aom', 'apart', 'apartment', 'apo', 'apologise', 'app', 'apparently', 'apple', 'applebees', 'application', 'apply', 'appointment', 'appreciate', 'appreciated', 'approx', 'apps', 'appt', 'april', 'aproach', 'ar', 'arcade', 'ard', 'area', 'aren', 'arent', 'argh', 'argue', 'argument', 'arm', 'armand', 'arng', 'arrange', 'arrested', 'arrive', 'arsenal', 'art', 'arun', 'asap', 'ashley', 'ask', 'askd', 'asked', 'askin', 'asking', 'asks', 'asleep', 'asp', 'assume', 'ate', 'atlanta', 'atlast', 'atm', 'attached', 'attempt', 'attend', 'auction', 'audition', 'audrey', 'august', 'aunt', 'aunty', 'auto', 'av', 'available', 'avatar', 'ave', 'avent', 'avoid', 'avoiding', 'await', 'awaiting', 'awake', 'award', 'awarded', 'away', 'awesome', 'aww', 'ayn', 'ba', 'babe', 'baby', 'bad', 'bag', 'bahamas', 'bak', 'balance', 'ball', 'bang', 'bank', 'bar', 'barely', 'base', 'basic', 'basically', 'bat', 'batch', 'bath', 'bathe', 'bathing', 'battery', 'battle', 'bay', 'bb', 'bbd', 'bc', 'bck', 'bcm', 'bcoz', 'bcums', 'bday', 'bear', 'beautiful', 'beauty', 'bec', 'becoz', 'bed', 'bedrm', 'bedroom', 'beer', 'befor', 'beg', 'begging', 'begin', 'behave', 'bein', 'believe', 'belive', 'bell', 'belly', 'belovd', 'beloved', 'ben', 'beneath', 'beneficiary', 'benefit', 'best', 'bet', 'better', 'beware', 'bf', 'bhaji', 'bid', 'big', 'bigger', 'biggest', 'billed', 'billion', 'bin', 'biola', 'bird', 'birla', 'birth', 'birthdate', 'birthday', 'bishan', 'bit', 'bitch', 'bite', 'biz', 'bk', 'black', 'blackberry', 'blah', 'blake', 'blame', 'blank', 'blanket', 'bleh', 'bless', 'blessed', 'blessing', 'blind', 'block', 'bloke', 'blonde', 'bloo', 'blood', 'bloody', 'bloomberg', 'blow', 'blu', 'blue', 'bluetooth', 'bluff', 'blur', 'bmw', 'boat', 'body', 'bold', 'bone', 'bonus', 'boo', 'book', 'booked', 'booking', 'boost', 'booty', 'bootydelious', 'bored', 'borin', 'boring', 'born', 'borrow', 'bos', 'boston', 'bother', 'bottle', 'bought', 'bout', 'bowl', 'box', 'boy', 'boye', 'boyfriend', 'boytoy', 'bp', 'brah', 'brain', 'brand', 'brandy', 'bray', 'bread', 'break', 'breath', 'breathe', 'brief', 'bright', 'brilliant', 'bring', 'bringing', 'brings', 'bristol', 'british', 'britney', 'bro', 'broad', 'broke', 'broken', 'bros', 'brothas', 'brother', 'brought', 'brownie', 'bruce', 'bruv', 'bslvyl', 'bstfrnd', 'bt', 'btw', 'buck', 'bud', 'buddy', 'budget', 'buff', 'buffet', 'bugis', 'build', 'building', 'bulb', 'bun', 'burger', 'burn', 'burning', 'bus', 'business', 'busy', 'butt', 'buy', 'buyer', 'buying', 'buzy', 'buzz', 'bx', 'bye', 'cabin', 'cafe', 'cake', 'cal', 'calculation', 'cali', 'calicut', 'california', 'callback', 'callcost', 'calld', 'called', 'caller', 'callertune', 'callfreefone', 'callin', 'calling', 'calm', 'cam', 'camcorder', 'came', 'camera', 'campus', 'canada', 'canal', 'canary', 'cancel', 'cancelled', 'cancer', 'cann', 'capital', 'cappuccino', 'captain', 'car', 'card', 'cardiff', 'care', 'cared', 'career', 'careful', 'carefully', 'caring', 'carlos', 'caroline', 'carry', 'cartoon', 'case', 'cash', 'cashbin', 'cashto', 'castor', 'cat', 'catch', 'catching', 'caught', 'cause', 'causing', 'cbe', 'cc', 'cd', 'cdgt', 'celeb', 'celebrate', 'celebration', 'cell', 'center', 'centre', 'certainly', 'ch', 'cha', 'chain', 'challenge', 'chance', 'change', 'changed', 'channel', 'character', 'charge', 'charged', 'charity', 'charles', 'chart', 'chase', 'chasing', 'chat', 'chatting', 'cheap', 'cheaper', 'cheat', 'cheating', 'chechi', 'check', 'checked', 'checking', 'cheer', 'chennai', 'chicken', 'chikku', 'child', 'childish', 'chill', 'chillin', 'china', 'chinese', 'choice', 'choose', 'chosen', 'christmas', 'church', 'cine', 'cinema', 'citizen', 'city', 'claim', 'claire', 'class', 'clean', 'cleaning', 'clear', 'cleared', 'click', 'clock', 'clos', 'close', 'closed', 'closer', 'club', 'cm', 'cn', 'cock', 'code', 'coffee', 'coin', 'cold', 'colleague', 'collect', 'collected', 'collecting', 'collection', 'college', 'colour', 'com', 'come', 'comedy', 'comin', 'coming', 'common', 'community', 'comp', 'company', 'competition', 'complete', 'completely', 'complimentary', 'computer', 'comuk', 'concentrate', 'concert', 'condition', 'confidence', 'confirm', 'confirmed', 'congrats', 'congratulation', 'connect', 'connection', 'considering', 'constantly', 'contact', 'contacted', 'content', 'contract', 'convey', 'cook', 'cooking', 'cool', 'copy', 'cornwall', 'correct', 'cost', 'costa', 'couldn', 'count', 'country', 'couple', 'course', 'cover', 'coz', 'cr', 'crab', 'crack', 'cramp', 'crave', 'crazy', 'cream', 'created', 'credit', 'credited', 'creepy', 'cricketer', 'crisis', 'crore', 'cross', 'croydon', 'cruise', 'csbcm', 'csh', 'ctxt', 'cud', 'cuddle', 'cuddling', 'cum', 'cup', 'curious', 'current', 'currently', 'curry', 'cust', 'custcare', 'custom', 'customer', 'cut', 'cute', 'cutefrnd', 'cuz', 'cw', 'da', 'dad', 'daddy', 'dai', 'daily', 'damn', 'dare', 'dark', 'darlin', 'darling', 'darren', 'dat', 'date', 'datebox', 'dating', 'datz', 'dave', 'day', 'dead', 'deal', 'dear', 'dearer', 'dearly', 'death', 'december', 'decide', 'decided', 'decimal', 'decision', 'deep', 'def', 'definitely', 'del', 'deleted', 'deliver', 'delivered', 'deliveredtomorrow', 'delivery', 'dem', 'den', 'depends', 'derek', 'dey', 'di', 'diamond', 'dick', 'dictionary', 'did', 'didn', 'didnt', 'die', 'died', 'diet', 'diff', 'difference', 'different', 'difficult', 'dificult', 'digital', 'dignity', 'din', 'dinner', 'dint', 'direct', 'directly', 'dirty', 'dis', 'discount', 'discus', 'dislike', 'display', 'distance', 'disturb', 'dload', 'dnt', 'doc', 'doctor', 'doe', 'doesn', 'doesnt', 'dog', 'dogging', 'doggy', 'doin', 'doing', 'dollar', 'don', 'dont', 'door', 'dot', 'double', 'download', 'downloads', 'draw', 'dream', 'dress', 'dressed', 'dresser', 'drink', 'drinking', 'drive', 'drivin', 'driving', 'drop', 'dropped', 'drug', 'drunk', 'dry', 'dsn', 'dubsack', 'dude', 'dun', 'dunno', 'dvd', 'ear', 'earlier', 'early', 'earth', 'easier', 'easy', 'eat', 'eaten', 'eatin', 'eating', 'ec', 'eerie', 'effect', 'egg', 'eh', 'em', 'email', 'embarassed', 'end', 'ended', 'ending', 'enemy', 'energy', 'eng', 'england', 'english', 'enjoy', 'enjoyed', 'enter', 'entered', 'entitled', 'entry', 'enuff', 'envelope', 'er', 'erm', 'error', 'escape', 'ese', 'especially', 'esplanade', 'essential', 'euro', 'eve', 'evening', 'event', 'everybody', 'evn', 'evng', 'evry', 'ex', 'exact', 'exactly', 'exam', 'excellent', 'exciting', 'excuse', 'exe', 'executive', 'exhausted', 'expect', 'expecting', 'expensive', 'experience', 'expires', 'explain', 'express', 'extra', 'eye', 'fa', 'face', 'facebook', 'fact', 'failed', 'fair', 'fall', 'family', 'fan', 'fancy', 'fantastic', 'fantasy', 'far', 'farm', 'fast', 'faster', 'fat', 'father', 'fathima', 'fault', 'fave', 'favor', 'favour', 'favourite', 'fb', 'fear', 'feb', 'february', 'fee', 'feel', 'feelin', 'feeling', 'fell', 'felt', 'female', 'fetch', 'fever', 'fight', 'fighting', 'fightng', 'figure', 'file', 'film', 'final', 'finally', 'fine', 'finger', 'finish', 'finished', 'finishing', 'fish', 'fit', 'fix', 'fixed', 'fl', 'flag', 'flaked', 'flash', 'flat', 'flight', 'flirt', 'floor', 'flower', 'fly', 'fml', 'follow', 'followed', 'following', 'fone', 'food', 'fool', 'foot', 'football', 'footprint', 'force', 'foreign', 'forever', 'forevr', 'forget', 'forgot', 'form', 'forum', 'forward', 'forwarded', 'fr', 'fran', 'freak', 'free', 'freefone', 'freemsg', 'freephone', 'freezing', 'fren', 'frens', 'fri', 'friday', 'friend', 'friendship', 'frm', 'frnd', 'frnds', 'frndship', 'frog', 'fromm', 'frying', 'fuck', 'fucked', 'fuckin', 'fucking', 'ful', 'fullonsms', 'fun', 'function', 'funeral', 'funk', 'funky', 'funny', 'furniture', 'future', 'fwd', 'fyi', 'ga', 'gain', 'gal', 'galileo', 'game', 'gamestar', 'ganesh', 'gang', 'gap', 'garage', 'garbage', 'garden', 'gardener', 'gary', 'gas', 'gastroenteritis', 'gautham', 'gave', 'gay', 'gaytextbuddy', 'gb', 'gbp', 'gd', 'ge', 'gee', 'geeee', 'geeeee', 'gender', 'generally', 'genius', 'gent', 'gentle', 'gentleman', 'gently', 'genuine', 'george', 'germany', 'getstop', 'gettin', 'getting', 'getzed', 'geva', 'gf', 'ghost', 'gift', 'gim', 'girl', 'girlfrnd', 'giv', 'given', 'giving', 'glad', 'gm', 'gn', 'goal', 'god', 'goin', 'going', 'gon', 'gona', 'gone', 'good', 'goodmorning', 'goodnight', 'goodnite', 'google', 'gorgeous', 'gossip', 'got', 'goto', 'govt', 'gr', 'grahmbell', 'gram', 'grand', 'gravity', 'great', 'green', 'greet', 'greeting', 'grin', 'grl', 'ground', 'group', 'gt', 'guaranteed', 'gud', 'gudnite', 'guess', 'guide', 'guilty', 'guy', 'gym', 'ha', 'haf', 'haha', 'hahaha', 'hai', 'hair', 'haiz', 'half', 'halloween', 'ham', 'hand', 'handed', 'handle', 'handset', 'hanging', 'happen', 'happend', 'happened', 'happening', 'happens', 'happiness', 'happy', 'hard', 'hardcore', 'harry', 'hasn', 'hate', 'hav', 'haven', 'havent', 'havin', 'having', 'havnt', 'head', 'headache', 'hear', 'heard', 'heart', 'heavy', 'hee', 'height', 'helen', 'hell', 'hella', 'hello', 'help', 'hey', 'hg', 'hi', 'hide', 'high', 'hill', 'hint', 'hip', 'history', 'hit', 'hiya', 'hl', 'hmm', 'hmmm', 'hmv', 'ho', 'hold', 'holder', 'holding', 'holiday', 'holla', 'hols', 'home', 'homeowner', 'hon', 'honey', 'honeybee', 'hook', 'hop', 'hope', 'hopefully', 'hoping', 'horny', 'horrible', 'hospital', 'hostel', 'hot', 'hotel', 'hour', 'house', 'hows', 'howz', 'hp', 'hr', 'http', 'hubby', 'hug', 'huh', 'hun', 'hungry', 'hunny', 'hurry', 'hurt', 'husband', 'hv', 'hw', 'iam', 'ibhltd', 'ibiza', 'ic', 'ice', 'id', 'idea', 'identifier', 'idiot', 'idk', 'ignore', 'ikea', 'il', 'ill', 'im', 'imagine', 'imma', 'immediately', 'important', 'impossible', 'inch', 'incident', 'include', 'including', 'inclusive', 'india', 'indian', 'infernal', 'info', 'inform', 'information', 'informed', 'inning', 'insha', 'inside', 'instantly', 'instead', 'instituitions', 'instruction', 'insurance', 'intelligent', 'intention', 'interested', 'interesting', 'interflora', 'internet', 'interview', 'intro', 'invader', 'invest', 'invite', 'invited', 'inviting', 'invnted', 'iouri', 'ip', 'ipad', 'ipod', 'iq', 'irritates', 'irritating', 'iscoming', 'ish', 'island', 'isn', 'isnt', 'issue', 'italian', 'itcould', 'item', 'itwhichturnedinto', 'itz', 'ive', 'iz', 'izzit', 'ja', 'jacket', 'jackpot', 'jada', 'james', 'jamster', 'jan', 'jane', 'january', 'japanese', 'jas', 'jason', 'java', 'jay', 'jaya', 'jazz', 'jd', 'jealous', 'jean', 'jen', 'jenny', 'jerry', 'jess', 'jesus', 'jhl', 'jia', 'jiayin', 'jiu', 'jo', 'joanna', 'job', 'jogging', 'john', 'join', 'joined', 'joining', 'joke', 'jokin', 'joking', 'jolly', 'jolt', 'jordan', 'journey', 'joy', 'jsco', 'jst', 'jstfrnd', 'jsut', 'juan', 'juicy', 'july', 'june', 'jus', 'just', 'juz', 'kadeem', 'kaiez', 'kallis', 'kano', 'kappa', 'karaoke', 'kate', 'kavalan', 'kay', 'kb', 'ke', 'keeping', 'kegger', 'kent', 'kept', 'kerala', 'keralacircle', 'kettoda', 'key', 'kg', 'kick', 'kickoff', 'kid', 'kidding', 'kidz', 'kill', 'killed', 'killing', 'kind', 'kinda', 'kindly', 'king', 'kiosk', 'kiss', 'kl', 'knackered', 'knee', 'knew', 'knock', 'know', 'knowing', 'knw', 'konw', 'kothi', 'kr', 'kudi', 'kusruthi', 'kz', 'la', 'lab', 'lac', 'lady', 'lag', 'laid', 'land', 'landline', 'lane', 'langport', 'language', 'laptop', 'lar', 'largest', 'late', 'lately', 'later', 'latest', 'latr', 'laugh', 'laughed', 'laughing', 'laundry', 'law', 'lay', 'lazy', 'lccltd', 'ldew', 'ldn', 'ldnw', 'le', 'lead', 'leaf', 'learn', 'leave', 'leaving', 'lect', 'lecture', 'left', 'leg', 'legal', 'leh', 'lei', 'lem', 'length', 'leona', 'lesson', 'let', 'letter', 'lf', 'liao', 'lib', 'library', 'lick', 'lido', 'lie', 'life', 'lifetime', 'lifpartnr', 'lift', 'light', 'lik', 'like', 'liked', 'likely', 'lil', 'lily', 'limit', 'limiting', 'line', 'linerental', 'link', 'lion', 'lionm', 'lionp', 'lip', 'list', 'listen', 'listening', 'literally', 'little', 'live', 'lived', 'liverpool', 'living', 'lk', 'll', 'lmao', 'lo', 'load', 'loan', 'local', 'location', 'lock', 'log', 'login', 'logo', 'lol', 'london', 'lonely', 'long', 'longer', 'look', 'lookatme', 'looked', 'lookin', 'looking', 'loose', 'lor', 'lose', 'loses', 'losing', 'loss', 'lost', 'lot', 'lotr', 'lotta', 'lou', 'loud', 'lounge', 'lousy', 'lov', 'lovable', 'love', 'loved', 'lovejen', 'lovely', 'loveme', 'lover', 'loverboy', 'loving', 'lovingly', 'low', 'lower', 'loxahatchee', 'loyal', 'loyalty', 'lp', 'lst', 'lt', 'lttrs', 'luck', 'lucky', 'lucozade', 'lucy', 'lunch', 'lush', 'luv', 'luvs', 'lux', 'luxury', 'lv', 'lvblefrnd', 'lyf', 'lyfu', 'lyk', 'ma', 'maangalyam', 'mac', 'machan', 'macho', 'mad', 'madam', 'mag', 'maga', 'magical', 'mah', 'mahal', 'maid', 'mail', 'mailbox', 'main', 'maintain', 'major', 'make', 'makin', 'making', 'malaria', 'male', 'mall', 'man', 'manage', 'managed', 'management', 'manda', 'mandan', 'maneesha', 'map', 'march', 'margaret', 'mark', 'market', 'marriage', 'married', 'marrow', 'marry', 'massage', 'massive', 'master', 'match', 'mate', 'math', 'mathematics', 'matrix', 'matter', 'matured', 'maturity', 'max', 'maximize', 'mayb', 'maybe', 'mb', 'mca', 'mcat', 'meal', 'mean', 'meaning', 'meant', 'measure', 'med', 'medical', 'medicine', 'meet', 'meetin', 'meeting', 'mega', 'meh', 'mei', 'mel', 'melle', 'melt', 'member', 'membership', 'memory', 'men', 'mental', 'menu', 'meow', 'merry', 'mesages', 'mess', 'message', 'messaged', 'messaging', 'messenger', 'messy', 'met', 'mi', 'mid', 'middle', 'midnight', 'mids', 'mila', 'mile', 'milk', 'million', 'min', 'mind', 'mini', 'minimum', 'minmobsmorelkpobox', 'minmoremobsemspobox', 'minnaminunginte', 'minor', 'minute', 'minuts', 'miracle', 'misbehaved', 'miserable', 'miss', 'missed', 'missin', 'missing', 'mistake', 'mite', 'mitsake', 'mix', 'mk', 'ml', 'mm', 'mmm', 'mmmm', 'mmmmm', 'mmmmmm', 'mnth', 'mnths', 'mo', 'moan', 'mob', 'mobile', 'mobilesdirect', 'mobileupd', 'mobno', 'moby', 'mode', 'model', 'module', 'moji', 'mojibiola', 'mokka', 'mom', 'moment', 'mon', 'monday', 'money', 'monkey', 'mono', 'month', 'monthly', 'mood', 'moon', 'moral', 'morefrmmob', 'morn', 'mornin', 'morning', 'moro', 'morow', 'morphine', 'morro', 'morrow', 'mother', 'motorola', 'mountain', 'mouth', 'moved', 'movie', 'movietrivia', 'moving', 'mp', 'mr', 'mrng', 'mrt', 'mrw', 'msg', 'msging', 'msgrcvd', 'msgrcvdhg', 'msn', 'mt', 'mtalk', 'mth', 'mths', 'mtmsg', 'mtmsgrcvd', 'mu', 'muah', 'mum', 'mummy', 'mumtaz', 'munsters', 'murder', 'murdered', 'murderer', 'music', 'musthu', 'muz', 'mystery', 'na', 'nag', 'nagar', 'nah', 'nahi', 'naked', 'nalla', 'named', 'nan', 'nanny', 'nap', 'nasdaq', 'nasty', 'nat', 'natalie', 'natalja', 'national', 'natural', 'nature', 'naughty', 'nb', 'nd', 'ne', 'near', 'nearly', 'necessarily', 'necessary', 'neck', 'necklace', 'ned', 'need', 'needed', 'neft', 'neighbor', 'neighbour', 'nervous', 'net', 'netcollex', 'network', 'networking', 'neva', 'new', 'neway', 'newest', 'news', 'ni', 'nic', 'nice', 'nichols', 'nigeria', 'night', 'nimya', 'nit', 'nite', 'nitros', 'noe', 'nok', 'nokia', 'nokias', 'noline', 'noon', 'nope', 'norm', 'normal', 'normally', 'northampton', 'note', 'nothin', 'notice', 'notxt', 'noun', 'nowadays', 'nt', 'ntt', 'ntwk', 'nu', 'num', 'number', 'nurungu', 'nuther', 'nvm', 'nw', 'nxt', 'ny', 'nyc', 'nydc', 'nyt', 'obviously', 'occupy', 'odi', 'offer', 'office', 'official', 'officially', 'ofice', 'oh', 'oi', 'oic', 'oil', 'ok', 'okay', 'okey', 'okie', 'ola', 'old', 'omg', 'omw', 'oni', 'onion', 'online', 'onwards', 'oooh', 'oops', 'open', 'opening', 'operator', 'opinion', 'opportunity', 'opt', 'option', 'optout', 'orange', 'orchard', 'order', 'ordered', 'oredi', 'oreo', 'orig', 'original', 'oru', 'oso', 'otside', 'outage', 'outside', 'outstanding', 'outta', 'ovulation', 'ow', 'owns', 'oz', 'pa', 'pack', 'package', 'page', 'paid', 'pain', 'painful', 'painting', 'pale', 'pan', 'pandy', 'panic', 'pap', 'paper', 'paperwork', 'paragon', 'parco', 'parent', 'paris', 'park', 'parked', 'parking', 'partner', 'partnership', 'party', 'pas', 'passed', 'passionate', 'password', 'past', 'path', 'pattern', 'patty', 'pay', 'payed', 'payee', 'paying', 'payment', 'payoh', 'pc', 'peace', 'peaceful', 'peak', 'pee', 'pen', 'pending', 'penis', 'penny', 'people', 'percent', 'perfect', 'period', 'permission', 'person', 'personal', 'personality', 'perwksub', 'pete', 'petey', 'petrol', 'pg', 'ph', 'philosophy', 'phne', 'phoenix', 'phone', 'phoned', 'photo', 'php', 'pic', 'pick', 'picked', 'picking', 'pickle', 'picsfree', 'picture', 'pie', 'piece', 'pig', 'pilate', 'pimple', 'pin', 'pink', 'piss', 'pissed', 'pix', 'pizza', 'place', 'placement', 'plan', 'plane', 'planet', 'planned', 'planning', 'play', 'played', 'player', 'playing', 'plaza', 'pleased', 'pleasure', 'plenty', 'plm', 'pls', 'plus', 'plz', 'pm', 'po', 'pobox', 'pocketbabe', 'pod', 'poem', 'point', 'poker', 'pole', 'police', 'politician', 'polo', 'poly', 'polyh', 'polyph', 'polyphonic', 'polys', 'pongal', 'pool', 'poop', 'poor', 'pop', 'popcorn', 'popped', 'porn', 'position', 'possession', 'possible', 'post', 'postcard', 'postcode', 'posted', 'potato', 'potential', 'potter', 'pouch', 'pound', 'pours', 'pout', 'power', 'pp', 'ppermesssubscription', 'ppl', 'pple', 'ppm', 'ppmx', 'ppw', 'prabha', 'practical', 'practice', 'practicing', 'pray', 'praying', 'pre', 'prefer', 'preferably', 'prem', 'premier', 'premium', 'prepaid', 'prepare', 'prepared', 'prepayment', 'prescription', 'present', 'press', 'pretty', 'previous', 'previously', 'prey', 'price', 'pride', 'prince', 'princess', 'print', 'printed', 'priscilla', 'privacy', 'private', 'prize', 'pro', 'prob', 'probably', 'problem', 'probs', 'process', 'processed', 'prof', 'professor', 'profile', 'profit', 'program', 'project', 'prolly', 'promise', 'promo', 'prompt', 'proof', 'properly', 'property', 'propose', 'propsd', 'prospect', 'protect', 'prove', 'proverb', 'provided', 'pt', 'ptbo', 'pub', 'public', 'pull', 'purchase', 'purity', 'purpose', 'purse', 'push', 'pussy', 'puttin', 'putting', 'pw', 'px', 'qatar', 'qp', 'qu', 'quality', 'queen', 'ques', 'question', 'questioned', 'quick', 'quickly', 'quiet', 'quit', 'quite', 'quiz', 'quote', 'quoting', 'qxj', 'racing', 'radio', 'raed', 'rael', 'railway', 'rain', 'raining', 'raise', 'raj', 'raji', 'rakhesh', 'rally', 'ran', 'random', 'randomly', 'randy', 'rang', 'range', 'ranjith', 'rate', 'ray', 'rcv', 'rcvd', 'rd', 'reach', 'reached', 'reaching', 'reaction', 'read', 'reader', 'reading', 'ready', 'real', 'realise', 'reality', 'realize', 'realized', 'really', 'realy', 'reason', 'reasonable', 'reboot', 'rec', 'recd', 'receipt', 'receive', 'receivea', 'received', 'receiving', 'recent', 'recently', 'recession', 'recharge', 'reckon', 'recognise', 'record', 'recovery', 'red', 'redeemed', 'reduce', 'ref', 'reference', 'refilled', 'refused', 'reg', 'regard', 'regarding', 'register', 'registered', 'regret', 'regular', 'relation', 'relative', 'relax', 'released', 'rem', 'remain', 'remains', 'remember', 'remembered', 'remembr', 'remind', 'reminder', 'reminding', 'removal', 'remove', 'removed', 'renewal', 'rent', 'rental', 'rentl', 'repair', 'repeat', 'replace', 'replacement', 'replied', 'reply', 'replying', 'report', 'representative', 'request', 'research', 'reserve', 'respect', 'respectful', 'responce', 'respond', 'responding', 'response', 'responsibility', 'rest', 'restaurant', 'result', 'resume', 'retrieve', 'return', 'returned', 'reveal', 'revealed', 'reverse', 'review', 'revision', 'reward', 'rewarding', 'rg', 'rgds', 'rhythm', 'rice', 'rich', 'ride', 'right', 'rightly', 'ring', 'ringtone', 'ringtoneking', 'ringtones', 'risk', 'rite', 'river', 'road', 'roast', 'rock', 'rofl', 'roger', 'role', 'romantic', 'ron', 'room', 'roommate', 'rose', 'round', 'row', 'royal', 'rply', 'rr', 'rstm', 'ru', 'rub', 'rude', 'ruin', 'ruining', 'rule', 'rum', 'rumour', 'run', 'running', 'rush', 'rw', 'ryan', 'sac', 'sachin', 'sacrifice', 'sad', 'sae', 'safe', 'said', 'sake', 'salam', 'salary', 'sale', 'salon', 'sam', 'santa', 'sar', 'sarasota', 'sarcasm', 'sarcastic', 'sary', 'sat', 'sathya', 'satisfied', 'satisfy', 'saturday', 'saucy', 'savamob', 'save', 'saved', 'saw', 'say', 'saying', 'scared', 'scary', 'sch', 'schedule', 'school', 'science', 'scold', 'score', 'scoring', 'scotch', 'scotland', 'scotsman', 'scream', 'screamed', 'screaming', 'screen', 'scrounge', 'sd', 'se', 'sea', 'search', 'searching', 'season', 'seat', 'sec', 'second', 'secret', 'secretary', 'secretly', 'section', 'sed', 'seed', 'seeing', 'seen', 'select', 'selected', 'selection', 'self', 'selfish', 'sell', 'selling', 'sem', 'semester', 'sen', 'send', 'sender', 'sending', 'sends', 'sense', 'sensitive', 'sent', 'sentence', 'senthil', 'sept', 'series', 'seriously', 'service', 'serving', 'set', 'setting', 'settle', 'settled', 'seven', 'sex', 'sexy', 'sh', 'sha', 'shagged', 'shahjahan', 'shall', 'shame', 'shampain', 'share', 'shared', 'sharing', 'shd', 'sheet', 'sheffield', 'shelf', 'shesil', 'shijas', 'shining', 'ship', 'shipped', 'shipping', 'shirt', 'shit', 'shitload', 'shld', 'shock', 'shocking', 'shoe', 'shoot', 'shop', 'shoppin', 'shopping', 'shore', 'short', 'shortage', 'shorter', 'shortly', 'shot', 'shouldn', 'shouted', 'shoving', 'shower', 'showing', 'shracomorsglsuplt', 'shu', 'shuhui', 'shut', 'shy', 'si', 'sian', 'sib', 'sick', 'sigh', 'sight', 'sign', 'signing', 'silence', 'silent', 'silently', 'silver', 'sim', 'simple', 'simpler', 'simply', 'sinco', 'sing', 'singing', 'single', 'sip', 'sipix', 'sir', 'sister', 'sit', 'site', 'sitll', 'sitting', 'situation', 'siva', 'size', 'sk', 'skilgme', 'skillgame', 'skip', 'sky', 'skype', 'skyped', 'slap', 'slave', 'sleep', 'sleepin', 'sleeping', 'slept', 'slice', 'slipper', 'slow', 'slowly', 'sm', 'small', 'smart', 'smile', 'smiling', 'smoke', 'smoking', 'smth', 'sn', 'snake', 'snow', 'social', 'sofa', 'soft', 'software', 'sol', 'solve', 'somebody', 'somethin', 'song', 'sony', 'sonyericsson', 'soon', 'sooner', 'sore', 'sorrow', 'sorry', 'sort', 'sorted', 'sorting', 'sory', 'soryda', 'sound', 'soup', 'source', 'south', 'sp', 'space', 'spanish', 'spare', 'speak', 'special', 'specially', 'speechless', 'speed', 'spell', 'spend', 'spending', 'spent', 'spk', 'spl', 'spoke', 'spoken', 'spook', 'sport', 'spree', 'spring', 'sry', 'st', 'staff', 'stamp', 'stand', 'standard', 'standing', 'star', 'start', 'started', 'starting', 'starwars', 'statement', 'station', 'stay', 'staying', 'std', 'step', 'stock', 'stockport', 'stomach', 'stomp', 'stone', 'stop', 'stopped', 'stoptxt', 'store', 'storming', 'story', 'str', 'straight', 'stranger', 'street', 'stress', 'stretch', 'strike', 'strip', 'strong', 'stuck', 'student', 'study', 'studying', 'stuff', 'stupid', 'style', 'stylish', 'sub', 'subpoly', 'subscribe', 'subscribed', 'subscriber', 'subscription', 'successful', 'successfully', 'suck', 'sugar', 'suggest', 'suite', 'sum', 'summer', 'sun', 'sunday', 'sunny', 'sunshine', 'suntec', 'sup', 'super', 'superb', 'superior', 'supervisor', 'supply', 'support', 'supposed', 'suprman', 'sura', 'sure', 'surely', 'surfing', 'surprise', 'surprised', 'sw', 'sweet', 'sweetest', 'swimming', 'swing', 'switch', 'swt', 'swtheart', 'symbol', 'ta', 'table', 'tablet', 'taken', 'takin', 'taking', 'talent', 'talk', 'talking', 'tampa', 'tape', 'tariff', 'tat', 'taunton', 'taylor', 'tb', 'tc', 'tcr', 'tea', 'teach', 'teacher', 'team', 'tear', 'tease', 'teasing', 'technical', 'teeth', 'tel', 'tell', 'telling', 'telphone', 'temp', 'temple', 'tenant', 'tenerife', 'term', 'terrible', 'tessy', 'test', 'text', 'textcomp', 'texted', 'texting', 'textoperator', 'textpod', 'tf', 'th', 'thangam', 'thank', 'thanks', 'thanksgiving', 'thanx', 'thats', 'theatre', 'themob', 'theory', 'thing', 'think', 'thinkin', 'thinking', 'thk', 'thm', 'thnk', 'tho', 'thought', 'threat', 'throat', 'throw', 'tht', 'thts', 'thurs', 'thursday', 'ti', 'tick', 'ticket', 'tihs', 'til', 'till', 'time', 'timing', 'tired', 'tirupur', 'title', 'tkts', 'tlp', 'tm', 'tmr', 'tncs', 'toa', 'toclaim', 'today', 'tog', 'told', 'toll', 'tom', 'tomarrow', 'tomo', 'tomorrow', 'tone', 'tonight', 'tonite', 'took', 'torch', 'tot', 'total', 'totally', 'touch', 'touched', 'tough', 'tour', 'town', 'track', 'trade', 'traffic', 'train', 'training', 'transaction', 'transfer', 'transfered', 'travel', 'treat', 'treated', 'tree', 'tried', 'trip', 'trouble', 'truck', 'true', 'truffle', 'truly', 'trust', 'truth', 'try', 'trying', 'tsandcs', 'tscs', 'tsunami', 'tt', 'ttyl', 'tues', 'tuesday', 'tuition', 'turn', 'tv', 'twice', 'txt', 'txtauction', 'txtin', 'txting', 'txts', 'tyler', 'type', 'tyrone', 'ubi', 'ugh', 'uk', 'umma', 'ummmmmaah', 'unable', 'uncle', 'understand', 'understanding', 'understood', 'uni', 'unique', 'university', 'unless', 'unlimited', 'unredeemed', 'unsold', 'unsub', 'unsubscribe', 'update', 'upgrade', 'upload', 'upset', 'upto', 'ur', 'urawinner', 'ure', 'urgent', 'urgently', 'urgnt', 'url', 'urn', 'urself', 'usc', 'use', 'used', 'user', 'usf', 'using', 'usual', 'usually', 'uz', 'vaazhthukkal', 'vale', 'valentine', 'valid', 'valuable', 'value', 'valued', 'various', 'vary', 'vava', 'vday', 've', 'vega', 'vegetable', 'verified', 'verify', 'version', 'vettam', 'vewy', 'vid', 'video', 'videochat', 'videophones', 'vijay', 'vikky', 'village', 'violated', 'violence', 'violet', 'vip', 'virgin', 'visionsms', 'visit', 'visitor', 'viva', 'vivek', 'vl', 'voda', 'vodafone', 'vodka', 'voice', 'voicemail', 'vomit', 'vomiting', 'vote', 'voucher', 'vry', 'vth', 'vu', 'wa', 'wah', 'waheed', 'waht', 'wait', 'waited', 'waitin', 'waiting', 'wake', 'waking', 'wale', 'walk', 'walked', 'walking', 'wall', 'wallpaper', 'walmart', 'wan', 'wana', 'want', 'wanted', 'wanting', 'wap', 'warm', 'warner', 'warning', 'warranty', 'wasn', 'waste', 'wasted', 'wat', 'watch', 'watching', 'water', 'watever', 'wating', 'wats', 'wave', 'waxsto', 'way', 'wb', 'wc', 'weak', 'weakness', 'wear', 'wearing', 'weather', 'web', 'website', 'wed', 'wedding', 'wednesday', 'wee', 'weed', 'week', 'weekend', 'weekly', 'weigh', 'weight', 'weird', 'weirdest', 'welcome', 'welp', 'wen', 'went', 'wer', 'wesley', 'west', 'westlife', 'wet', 'whats', 'whatsup', 'whenevr', 'white', 'whn', 'whr', 'wicklow', 'wid', 'widelive', 'wif', 'wife', 'wifi', 'wihtuot', 'wil', 'willing', 'win', 'winaweek', 'winawk', 'wind', 'window', 'wine', 'winner', 'winning', 'wipro', 'wisdom', 'wise', 'wish', 'wishin', 'wishing', 'wiskey', 'wit', 'wiv', 'wk', 'wkend', 'wkent', 'wkg', 'wkly', 'wks', 'wld', 'wml', 'wn', 'wnt', 'wo', 'woke', 'woken', 'woman', 'won', 'wonder', 'wonderful', 'wondering', 'wont', 'woot', 'word', 'work', 'workin', 'working', 'world', 'worried', 'worry', 'worse', 'worst', 'worth', 'wot', 'woulda', 'wouldn', 'wow', 'wp', 'wq', 'wrc', 'write', 'wrk', 'wrnog', 'wrong', 'wrote', 'wt', 'wtf', 'wu', 'wud', 'wuld', 'wun', 'www', 'wx', 'wylie', 'xam', 'xavier', 'xchat', 'xh', 'xin', 'xmas', 'xn', 'xuhui', 'xx', 'xxx', 'xxxmobilemovieclub', 'xxxx', 'xxxxx', 'xxxxxx', 'xxxxxxx', 'xxxxxxxxx', 'xy', 'ya', 'yahoo', 'yan', 'yar', 'yarasu', 'yay', 'yck', 'yeah', 'year', 'yeh', 'yelling', 'yellow', 'yep', 'yer', 'yes', 'yest', 'yesterday', 'yetunde', 'yf', 'yijue', 'ym', 'yo', 'yoga', 'yogasana', 'yor', 'youre', 'yr', 'yummy', 'yun', 'yunny', 'yuo', 'yup', 'zed', 'zindgi', 'zoe']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "max_features = 3000\n",
    "count_vectorizer = CountVectorizer(max_features = max_features, stop_words = \"english\")\n",
    "sparce_matrix = count_vectorizer.fit_transform(description_list).toarray()\n",
    "print(\"Самые часто встречаемые {} слов: {}\".format(max_features,count_vectorizer.get_feature_names()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чаще всего во всех сообщениях встречается слово 'crazy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pH1JagoUelrD",
    "outputId": "40052921-4c09-4161-f91e-847e5419b63b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "592\n"
     ]
    }
   ],
   "source": [
    "list_names = count_vectorizer.get_feature_names()\n",
    "for i in range(len(list_names)):\n",
    "    if list_names[i] == 'crazy':\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wbDY56XWV7do"
   },
   "source": [
    "Исходные данные преобразуем в bag-of-words формат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "uJB0dstJfO7J",
    "outputId": "257b248e-7c2f-43a0-b44c-180930b6e01c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparce_matrix[0, 592]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "k8yCXDOfWAww",
    "outputId": "cba53e0e-5d41-4385-8e96-a8df9ec72589"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n"
     ]
    }
   ],
   "source": [
    "print(len(sparce_matrix[0,: ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9e24S-P4Vsrr"
   },
   "outputs": [],
   "source": [
    "y = data.iloc[:,0].values\n",
    "x = sparce_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dCv03et0WW5L"
   },
   "source": [
    "Делим данные на тренировочные и тестовые"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rF67b7VdV2VK"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tFi1KFI8WaWS"
   },
   "source": [
    "Напишем **наивный байесовский классификатор**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Ls-QwJfpWNVH",
    "outputId": "9aeb4a8e-899d-4b7d-e277-c91e0f230391"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy of our model: 0.8753363228699551\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb = GaussianNB()\n",
    "nb.fit(x_train,y_train)\n",
    "print(\"the accuracy of our model: {}\".format(nb.score(x_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "u9D5KTE6h19S",
    "outputId": "d5f5aca2-1a57-47a1-ed15-33a73a7c68eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.87      0.92       966\n",
      "           1       0.52      0.89      0.66       149\n",
      "\n",
      "    accuracy                           0.88      1115\n",
      "   macro avg       0.75      0.88      0.79      1115\n",
      "weighted avg       0.92      0.88      0.89      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, nb.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hRdUt0ThWe30"
   },
   "source": [
    "Напишем логистическую регрессию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "epQOa7FRWhqS",
    "outputId": "a27256ad-c076-4170-e7de-b8768fa35ba8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "our accuracy is: 0.9820627802690582\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(max_iter = 200)\n",
    "lr.fit(x_train,y_train)\n",
    "print(\"our accuracy is: {}\".format(lr.score(x_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "LNyFu4X1iabe",
    "outputId": "77ef3195-b21d-4b15-96b5-9d4595bb8d19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       966\n",
      "           1       1.00      0.87      0.93       149\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.99      0.93      0.96      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, lr.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cWc_Fs10W71Y"
   },
   "source": [
    "Классификатор по методу ближайшего соседа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "-05vUVlPW6Ey",
    "outputId": "96718b84-2014-4f48-a713-3964037917b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With KNN (K=3) accuracy is:  0.9399103139013453\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "knn.fit(x_train,y_train)\n",
    "#print('Prediction: {}'.format(prediction))\n",
    "print('With KNN (K=3) accuracy is: ',knn.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "dIrdoC-7igLs",
    "outputId": "b2da12cd-3931-40e0-a1d9-e12002f1db1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       966\n",
      "           1       1.00      0.55      0.71       149\n",
      "\n",
      "    accuracy                           0.94      1115\n",
      "   macro avg       0.97      0.78      0.84      1115\n",
      "weighted avg       0.94      0.94      0.93      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, knn.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZSGytE8OisyJ"
   },
   "source": [
    "Из всех выбранных моделей лучше всего дала результаты модель логистической регрессии."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ri6UgBXQoBnb"
   },
   "source": [
    "# Задача - определить класс, к которому относится тот или иной текст"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RnbwL_5mrS8U"
   },
   "source": [
    "Удаляем слова, которые не имеют смысловой нагрузки (например, слова 'и', 'или', 'а' и другие)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "oQvN2BL-ojtl",
    "outputId": "4ecec07f-4c6e-4234-b7fd-2c9450b24c7a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/yustinaivanova/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "import string\n",
    "import re\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(line):\n",
    "    word_tokens = word_tokenize(line)\n",
    "    filtered_sentence = [w for w in word_tokens if not w in stop_words] \n",
    "    return \" \".join(filtered_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sbMjGkOgr4QA"
   },
   "source": [
    "Далее функция, с помощью которой мы будем обрабатывать твиты\n",
    "\n",
    "\n",
    "*   переводим все слова в строчные буквы\n",
    "*   удаляем цифры\n",
    "*   удаляем пунктуацию\n",
    "*   удаляем стоп-слова\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3qfvy75XrDtU"
   },
   "outputs": [],
   "source": [
    "def preprocess(line):\n",
    "  # все слова переводим в строчный текст\n",
    "    line = line.lower()\n",
    "  # удаляем цифры\n",
    "    line = re.sub(r'\\d+', '', line)\n",
    "  # удаляем пунктуацию\n",
    "    line = line.translate(line.maketrans(\"\",\"\", string.punctuation))\n",
    "    line = remove_stopwords(line)\n",
    "    return line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z-I5nlmNsmpZ"
   },
   "source": [
    "Предобработка всех твитов из таблицы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "eHtyWq8NrA8H",
    "outputId": "b34dd777-5531-4878-e459-fc4a7e76ab02"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yustinaivanova/venv/venv/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "train = data\n",
    "\n",
    "for i,line in enumerate(train.tweet):\n",
    "    train.tweet[i] = preprocess(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>user father dysfunctional selfish drags kids d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>user user thanks lyft credit cant use cause do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>model love u take u time urð± ðððð...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide society motivation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31957</th>\n",
       "      <td>31958</td>\n",
       "      <td>0</td>\n",
       "      <td>ate user isz youuuððððððð...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31958</th>\n",
       "      <td>31959</td>\n",
       "      <td>0</td>\n",
       "      <td>see nina turner airwaves trying wrap mantle ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31959</th>\n",
       "      <td>31960</td>\n",
       "      <td>0</td>\n",
       "      <td>listening sad songs monday morning otw work sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31960</th>\n",
       "      <td>31961</td>\n",
       "      <td>1</td>\n",
       "      <td>user sikh temple vandalised calgary wso condem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31961</th>\n",
       "      <td>31962</td>\n",
       "      <td>0</td>\n",
       "      <td>thank user follow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31962 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label                                              tweet\n",
       "0          1      0  user father dysfunctional selfish drags kids d...\n",
       "1          2      0  user user thanks lyft credit cant use cause do...\n",
       "2          3      0                                     bihday majesty\n",
       "3          4      0  model love u take u time urð± ðððð...\n",
       "4          5      0                      factsguide society motivation\n",
       "...      ...    ...                                                ...\n",
       "31957  31958      0  ate user isz youuuððððððð...\n",
       "31958  31959      0  see nina turner airwaves trying wrap mantle ge...\n",
       "31959  31960      0    listening sad songs monday morning otw work sad\n",
       "31960  31961      1  user sikh temple vandalised calgary wso condem...\n",
       "31961  31962      0                                  thank user follow\n",
       "\n",
       "[31962 rows x 3 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JqH38PT5sb47"
   },
   "source": [
    "Разделим датасет на тренировочный и тестовый"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "xqF08sLBsapA",
    "outputId": "1cdd02bb-6a53-4d7e-e37b-3ebc683f61b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2242 entries, 13 to 31960\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      2242 non-null   int64 \n",
      " 1   label   2242 non-null   int64 \n",
      " 2   tweet   2242 non-null   object\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 70.1+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 29720 entries, 0 to 31961\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      29720 non-null  int64 \n",
      " 1   label   29720 non-null  int64 \n",
      " 2   tweet   29720 non-null  object\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 928.8+ KB\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train['tweet'], train['label'], \n",
    "                                                    test_size=0.5, stratify=train['label'])\n",
    "\n",
    "trainp=train[train.label==1]\n",
    "trainn=train[train.label==0]\n",
    "print(trainp.info())\n",
    "trainn.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MEBfXJvFstxJ"
   },
   "source": [
    "Можно заметить, что классы **несбалансированы**: в классе 1 2242 элемента, а в классе 0 их 29720. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jZzvozfItINL"
   },
   "source": [
    "Создадим bag-of-words вектора для всех твитов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jNcOfFrDtNoU"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "vect = CountVectorizer()\n",
    "tf_train=vect.fit_transform(X_train)  #train the vectorizer, build the vocablury\n",
    "tf_test=vect.transform(X_test)  #get same encodings on test data as of vocabulary built"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xz_uoxWUtRJl"
   },
   "source": [
    "Создадим модель **Наивный байес**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EcwwEUNHtTA7"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model = MultinomialNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jdihWKR6tlbR"
   },
   "source": [
    "Обучим модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "lpthYn7htjiG",
    "outputId": "d7bfa8ba-a61f-49d5-b306-52a5d386b5b6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X=tf_train,y=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wOKUfO3JtoKC"
   },
   "source": [
    "Посмотрим качество модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "x--lPL7Jtosu",
    "outputId": "bb7dca9f-aca6-4953-c339-d2108ae34e7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98     14860\n",
      "           1       0.89      0.43      0.58      1121\n",
      "\n",
      "    accuracy                           0.96     15981\n",
      "   macro avg       0.92      0.71      0.78     15981\n",
      "weighted avg       0.95      0.96      0.95     15981\n",
      "\n",
      "[[14798    62]\n",
      " [  642   479]]\n"
     ]
    }
   ],
   "source": [
    "expected = y_test\n",
    "predicted=model.predict(tf_test)\n",
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e5hNKWCVtzkb"
   },
   "source": [
    "Можно заметить, что класс 1 предсказывается намного хуже, чем класс 0: класса 1 намного меньше по числу элементов, чем класс 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EkZX9ROIt_1f"
   },
   "source": [
    "Сбалансируем датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "mnkYC-snuOHP",
    "outputId": "77fa6a69-6116-4913-ee62-093180fc751d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before\n",
      "0    29720\n",
      "1     2242\n",
      "Name: label, dtype: int64\n",
      "After\n",
      "1    29720\n",
      "0    29720\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_imbalanced = train\n",
    "from sklearn.utils import resample\n",
    "df_majority = train[train.label==0]\n",
    "df_minority = train[train.label==1]\n",
    " \n",
    "# Upsample minority class\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=len(df_majority),    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    " \n",
    "# Combine majority class with upsampled minority class\n",
    "df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    " \n",
    "# Display new class counts\n",
    "print(\"Before\")\n",
    "print(train.label.value_counts())\n",
    "print(\"After\")\n",
    "print(df_upsampled.label.value_counts())\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_upsampled['tweet'], df_upsampled['label'], test_size=0.5, stratify=df_upsampled['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QwutTun8xX2I"
   },
   "source": [
    "Можно заметить, что тренировочных данных стало больше, и классы уравнялись в количестве."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "NoD2ivRazam6",
    "outputId": "a4b034e7-53ee-4349-d67d-629f48fe2188"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.92      0.94     14860\n",
      "           1       0.92      0.97      0.94     14860\n",
      "\n",
      "    accuracy                           0.94     29720\n",
      "   macro avg       0.94      0.94      0.94     29720\n",
      "weighted avg       0.94      0.94      0.94     29720\n",
      "\n",
      "Матрица confusion\n",
      "[[13612  1248]\n",
      " [  458 14402]]\n"
     ]
    }
   ],
   "source": [
    "tf_train=vect.transform(X_train)\n",
    "tf_test=vect.transform(X_test)\n",
    "model.fit(X=tf_train,y=y_train)\n",
    "expected = y_test\n",
    "predicted=model.predict(tf_test)\n",
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print('Матрица confusion')\n",
    "print(metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GA-HqiesgQGd"
   },
   "source": [
    "Можно заметить, что балансировка привела к улучшению результата."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "4hzAP6kG0qCb",
    "J0t8bCoH8rIS"
   ],
   "include_colab_link": true,
   "name": "lecture_5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
