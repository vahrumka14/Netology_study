{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание к лекции \"Основы веб-скрапинга и работы с API\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1. \n",
    "\n",
    "### Обязательная часть"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем парсить страницу со свежеми новостям на [habr.com](https://habr.com/ru/all/).\n",
    "\n",
    "Вам необходимо собирать только те статьи, в которых встречается хотя бы одно требуемое ключевое слово. Эти слова определяем в начале кода в переменной, например:\n",
    "\n",
    "`KEYWORDS = ['python', 'парсинг']`\n",
    "\n",
    " Поиск вести по всей доступной preview-информации (это информация, доступная непосредственно с текущей страницы). \n",
    " \n",
    "В итоге должен формироваться датафрейм со столбцами: <дата> - <заголовок> - <ссылка>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEYWORDS = ['python', 'парсинг', 'kubernetes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# получаем страницу с самыми свежими постами\n",
    "req = requests.get('https://habr.com/ru/all/')\n",
    "soup = BeautifulSoup(req.text, 'html.parser')\n",
    "#soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# извлекаем посты\n",
    "posts = soup.find_all('article', class_='post')\n",
    "#posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "post 521080\n",
      "post 520568\n",
      "post 520800\n",
      "post 521072\n",
      "post 521070\n",
      "post 521064\n",
      "post 521058\n",
      "post 521056\n",
      "post 515114\n",
      "post 520666\n",
      "post 521046\n",
      "post 521044\n",
      "post 521040\n",
      "post 521034\n",
      "post 520858\n",
      "post 521032\n",
      "post 521028\n",
      "post 521020\n",
      "post 520892\n"
     ]
    }
   ],
   "source": [
    "for post in posts:\n",
    "    post_id = post.parent.attrs.get('id')\n",
    "   # если идентификатор не найден, это что-то странное, пропускаем\n",
    "    if not post_id:\n",
    "        continue\n",
    "    post_id = int(post_id.split('_')[-1])\n",
    "    print('post', post_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "сегодня в 18:00 Автоскейлинг приложений Kubernetes при помощи Prometheus и KEDA https://habr.com/ru/company/mailru/blog/515114/ mail.ru cloud solutions, kubernetes, k8s, prometheus, helm\n"
     ]
    }
   ],
   "source": [
    "for post in posts:\n",
    "    post_id = post.parent.attrs.get('id')\n",
    "    time.sleep(0.3)\n",
    "   # если идентификатор не найден, это что-то странное, пропускаем\n",
    "    if not post_id:\n",
    "        continue\n",
    "    post_id = int(post_id.split('_')[-1])\n",
    "    title_element = post.find('a', class_='post__title_link')\n",
    "    date = post.find('span', class_='post__time')\n",
    "    res = requests.get(title_element.attrs.get('href'))\n",
    "    soup = BeautifulSoup(res.text)\n",
    "    ke = soup.find('meta', attrs={'name':'keywords'})['content']\n",
    "    for j in KEYWORDS:\n",
    "        if j in ke:\n",
    "            print(date.text, title_element.text, title_element.attrs.get('href'), ke)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Дополнительная часть (необязательная)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Улучшить скрипт так, чтобы он анализировал не только preview-информацию статьи, но и весь текст статьи целиком.\n",
    "\n",
    "Для этого потребуется получать страницы статей и искать по тексту внутри этой страницы.\n",
    "\n",
    "Итоговый датафрейм формировать со столбцами: <дата> - <заголовок> - <ссылка> - <текст статьи>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "сегодня в 18:00 Автоскейлинг приложений Kubernetes при помощи Prometheus и KEDA https://habr.com/ru/company/mailru/blog/515114/\n",
      "mail.ru cloud solutions, kubernetes, k8s, prometheus, helm\n",
      "сегодня в 16:55 10 лучших программ для мониторинга цен конкурентов https://habr.com/ru/post/521028/\n",
      "Всем привет! Меня зовут Лиза, я изучала существующие решения по парсингу сайтов для того, чтобы отслеживать цены конкурентов моего интернет-магазина.\n",
      "Сервисы мониторинга цен конкурентов довольно различны, каждый имеет свою специфику работы, свои преимущества и недостатки. Ниже приведен список самых \n"
     ]
    }
   ],
   "source": [
    "for post in posts:\n",
    "    post_id = post.parent.attrs.get('id')\n",
    "    time.sleep(0.3)\n",
    "    if not post_id:\n",
    "        continue\n",
    "    post_id = int(post_id.split('_')[-1])\n",
    "    title_element = post.find('a', class_='post__title_link')\n",
    "    date = post.find('span', class_='post__time')\n",
    "    res = requests.get(title_element.attrs.get('href'))\n",
    "    soup = BeautifulSoup(res.text)\n",
    "    if soup.find('div', class_='post__text post__text-html post__text_v1'):\n",
    "        text_article = soup.find('div', class_='post__text post__text-html post__text_v1').text\n",
    "    elif soup.find('div', class_='post__text post__text-html post__text_v2'):\n",
    "        text_article = soup.find('div', class_='post__text post__text-html post__text_v2').text\n",
    "    ta = text_article.lower().strip()\n",
    "    ta1 = re.split(r'\\W+', ta)\n",
    "    ke = soup.find('meta', attrs={'name':'keywords'})['content']\n",
    "    for j in KEYWORDS:\n",
    "        if j in ke:\n",
    "            print(date.text, title_element.text, title_element.attrs.get('href'))\n",
    "            print(ke)\n",
    "        else:\n",
    "            if j in ta1:\n",
    "                print(date.text, title_element.text, title_element.attrs.get('href'))\n",
    "                print(text_article[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обязательная часть"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Написать скрипт, который будет проверять список e-mail адресов на утечку при помощи сервиса [Avast Hack Ckeck](https://www.avast.com/hackcheck/).\n",
    "Список email-ов задаем переменной в начале кода:  \n",
    "`EMAIL = [xxx@x.ru, yyy@y.com]`\n",
    "\n",
    "В итоге должен формироваться датафрейм со столбцами: <почта> - <дата утечки> - <источник утечки> - <описание утечки>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Дополнительная часть (необязательная)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Написать скрипт, который будет получать 50 последних постов указанной группы во Вконтакте.  \n",
    "Документация к API VK: https://vk.com/dev/methods\n",
    "```\n",
    "GROUP = 'netology'\n",
    "TOKEN = УДАЛЯЙТЕ В ВЕРСИИ ДЛЯ ПРОВЕРКИ, НА GITHUB НЕ ВЫКЛАДЫВАТЬ\n",
    "```\n",
    "\n",
    "В итоге должен формироваться датафрейм со столбцами: <дата поста> - <текст поста>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ПРИМЕЧАНИЕ\n",
    "Домашнее задание сдается ссылкой на репозиторий [GitHub](https://github.com/).\n",
    "Не сможем проверить или помочь, если вы пришлете:\n",
    "- файлы;\n",
    "- архивы;\n",
    "- скриншоты кода.\n",
    "\n",
    "Все обсуждения и консультации по выполнению домашнего задания ведутся только на соответствующем канале в slack.\n",
    "\n",
    "##### Как правильно задавать вопросы аспирантам, преподавателям и коллегам?\n",
    "Прежде чем задать вопрос необходимо попробовать найти ответ самому в интернете. Навык самостоятельного поиска информации – один из важнейших, и каждый практикующий специалист любого уровня это делает каждый день.\n",
    "\n",
    "Любой вопрос должен быть сформулирован по алгоритму:  \n",
    "1) Что я делаю?  \n",
    "2) Какого результата я ожидаю?  \n",
    "3) Как фактический результат отличается от ожидаемого?  \n",
    "4) Что я уже попробовал сделать, чтобы исправить проблему?  \n",
    "\n",
    "По возможности, прикрепляйте к вопросу скриншоты, либо ссылки на код. Оставляйте только проблемный и воспроизводимый участок кода, все решение выкладывать не допускается.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
